{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6773687e-eb23-4469-9730-d43ba409ca68",
   "metadata": {},
   "source": [
    "OSNN Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068af2d-7fe0-478c-924a-a76f69c1c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_and_save import *\n",
    "from centers_training import *\n",
    "from width_update import *\n",
    "from predict_function import *\n",
    "from calc_pseudolabels import *\n",
    "from weight_update import *\n",
    "from calc_CEL import *\n",
    "from evaluation_functions import *\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1268e71-37ca-4046-8dd8-7f2a6df56d6f",
   "metadata": {},
   "source": [
    "The function below is to remove unlabelled samples from the batch if we wish to do supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94827798-756b-4c82-a9ac-4ec223e76a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unlabelled_samples(batch):\n",
    "    '''\n",
    "    This function removes the unlabelled datapoints to convert the model into supervised learning.\n",
    "    Returns an empty array with the correct shape if there are no labeled samples.\n",
    "    '''\n",
    "    filtered_batch = [sample for sample in batch if sample[-1] != -1]\n",
    "    \n",
    "    if len(filtered_batch) == 0:\n",
    "        #return an empty array with the correct number of columns (e.g., 14)\n",
    "        return np.empty((0, batch.shape[1]))\n",
    "    \n",
    "    return np.array(filtered_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d58de3-c842-45e6-91db-b09e604ee29e",
   "metadata": {},
   "source": [
    "Below is the main OSNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82220c5d-645e-499d-a3f9-c063730eba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSNN(D, N, H, lam, alpha, beta, gamma, type=0):\n",
    "    '''\n",
    "    The main body of the OSNN algorithm. This model assumes that the number of neurons is less than the chunk size (i.e, H < N)\n",
    "\n",
    "    parameters:\n",
    "    - type : 1 for supervised, 0 for semisupervised\n",
    "    - D : dataset\n",
    "    - N : chunk size\n",
    "    - H : number of neurons in the network\n",
    "    - lam : manifold regularisation term\n",
    "    - alpha : L2 regularisation term\n",
    "    - beta : RBF_width\n",
    "    - gamma : RBFN_width\n",
    "\n",
    "    returns:\n",
    "    - the predictions made, this is given as a numpy array structured as [predicted_probability, predicted_class, true_label, assigned_label]\n",
    "    - the trained model at the final time step\n",
    "        - The weights\n",
    "        - The centers\n",
    "        - The widths \n",
    "    '''\n",
    "\n",
    "    #fix a seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    #initialise the algorithm\n",
    "    t = 0\n",
    "    C = np.empty((0, 14)) #there are 14 columns as each input has 14 attributes, change 14 to the appropriate amount\n",
    "    w = np.empty((0, 0)) #an empty list\n",
    "    batch = np.empty((0, 15)) #similar to C but two extra columns for 'contains_bug' and 'true_label', change 15 to the appropriate amount\n",
    "\n",
    "    #initialise a list to store predicted values and its true label\n",
    "    predictions = np.empty((0,4))\n",
    "\n",
    "    while t < 10000: #while there is data remaining in the dataset\n",
    "\n",
    "        if t%250 == 0: #to track the progress of the algorithm\n",
    "            print(t)\n",
    "        \n",
    "        #set current batch\n",
    "        if len(batch) < N: #if the size of the batch is less than the chunk size, \n",
    "            batch = np.vstack((batch, D[t][:-1])) #append the most recent sample\n",
    "        else:\n",
    "            batch = D[t-N+1:t+1,:-1] #otherwise set the batch to be the N most recent samples\n",
    "\n",
    "        #if we are setting the model to be supervised only, we remove the unlabelled data in the batch\n",
    "        if type == 1:\n",
    "            batch = remove_unlabelled_samples(batch)\n",
    "\n",
    "        #if the batch is empty:\n",
    "        if len(batch) == 0: \n",
    "            #if there are no centers or weights, then there's nothing to predict so move to the next time step\n",
    "            if C.size == 0 or w.size == 0:\n",
    "                t += 1\n",
    "            #if there are centers and weights and the batch is empty, then just predict the next sample using the current weights, \n",
    "            #centers and widths and move to the next time step.\n",
    "            else:\n",
    "                prob = predict(D[t+1], C, widths, w)\n",
    "                s = 0 if prob < 0.5 else 1\n",
    "                #store probability, prediction, true label, and 'contains bug' label\n",
    "                predictions = np.vstack((predictions, [prob, s, D[t+1,-1], D[t+1,-2]]))\n",
    "                t += 1\n",
    "\n",
    "        #if the batch is not empty, then see if we need to add centers, add them, else, train them, update, predict, and move to the next time step\n",
    "        else:\n",
    "            \n",
    "            if len(C) < H: \n",
    "                #while the number of centers is less than the number of neurons that we assigned\n",
    "                #this is to ensure that we have enough centers for all the nodes of the network before we begin training\n",
    "                \n",
    "                #add that sample to the set of centers\n",
    "                C = np.vstack((C, D[t][0:14])) #[0:14] ensures that only the attributes columns are added and the contains_bug and true label columns are excluded\n",
    "                \n",
    "                #initialise a new weight for that center\n",
    "                w = np.append(w, np.random.normal(0, 0.1))\n",
    "                \n",
    "            else:\n",
    "                #train centers\n",
    "                C = train_centers(C, batch)\n",
    "            \n",
    "            #update the widths using the centers and the RBF width parameter, beta\n",
    "            widths = update_widths(C, beta)\n",
    "    \n",
    "            #to calculate the pseudolabels and crossentropy loss, we require the predicted values of all samples in the batch, and the centers\n",
    "            pred = predict_multiple(batch, C, widths, w)\n",
    "            c_pred = predict_multiple(C, C, widths, w)\n",
    "            \n",
    "            #set learning rate eta = 1 and a stopping point epsilon. (epsilon is a user parameter that'll require experimenting with)\n",
    "            eta = 1\n",
    "            epsilon = 0.0039 # =2^-8\n",
    "    \n",
    "            while eta > epsilon:\n",
    "                #calc pseudolabels using centers, batch,\n",
    "                mu = pseudolabels_calc(C, batch, pred, c_pred, alpha, gamma)  \n",
    "                \n",
    "                #update the weights\n",
    "                w_new = update_weights(w, batch, pred, mu, alpha, lam, C, widths, eta)\n",
    "                pred_w_new = predict_multiple(batch, C, widths, w_new)\n",
    "                \n",
    "                #if the loss of the new weights is less than the loss of the current weights, set the new weights as the current weights\n",
    "                if cross_entropy_loss(batch, pred_w_new, mu, w_new, alpha, lam) < cross_entropy_loss(batch, pred, mu, w, alpha, lam):\n",
    "                    w = w_new\n",
    "                    break #breaks out of the 'while eta > epsilon:' loop\n",
    "                else:\n",
    "                    eta = eta/2\n",
    "    \n",
    "            \n",
    "            prob = predict(D[t+1], C, widths, w)\n",
    "            s = 0 if prob < 0.5 else 1\n",
    "            #store probability, prediction, true label, and 'contain's bug' label\n",
    "            predictions = np.vstack((predictions, [prob, s, D[t+1,-1], D[t+1,-2]]))\n",
    "    \n",
    "            t += 1\n",
    "    \n",
    "    return predictions #, C, widths, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bf8ed-348b-42f4-9f58-e54dd8b38c2e",
   "metadata": {},
   "source": [
    "Below is testing random numbers drawn from appropriate distributions for N, H, lam, alpha, beta, and gamma\n",
    "\n",
    "First we choose and random seed to always draw the same parameters to test for both the supervised and semisupervised tests\n",
    "\n",
    "Next I draw numbers for the parameter. The experiment is done with 50 different settings for each parameter, namely, N, H, lambda, alpha, beta, and gamma.\n",
    "\n",
    "- N : uniformly from [2,160]\n",
    "  \n",
    "- H : uniformly from [1, max(⌈N/4⌉, 10)]\n",
    "\n",
    "- lambda : uniformly from [0,1]\n",
    "\n",
    "- alpha : uniformly from [0,1]\n",
    "\n",
    "- beta : exponential distribution with mean = 1\n",
    "\n",
    "- gamma : exponential distribution with mean = 2\n",
    "\n",
    "Below is the results of drawing these random parameters with a fixed seed of 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df96768-1648-42fe-8483-3f8fe6d84765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix seed\n",
    "np.random.seed(70)\n",
    "\n",
    "#select 50x integers for N from [2,150]\n",
    "N_params = np.random.randint(2,160, 50)\n",
    "\n",
    "#select 50x integers for H from [1, N]\n",
    "H_params = []\n",
    "for i in range(50):\n",
    "    H_params.append(np.random.randint(1, max(np.ceil(N_params[i]/4), 10)))\n",
    "H_params = np.array(H_params)\n",
    "\n",
    "#select 50x floats for lambda and alpha from [0,1]\n",
    "lam_params = np.random.uniform(0, 1, 50)\n",
    "alpha_params = np.random.uniform(0, 1, 50)\n",
    "\n",
    "#select 50x floats for beta from exp distib with mean = 1\n",
    "beta_params = np.random.exponential(scale=1, size=50)\n",
    "\n",
    "#select 50x floats for gamma from exp distib with mean = 2\n",
    "gamma_params = np.random.exponential(scale=2, size=50)\n",
    "\n",
    "\n",
    "#selecet\n",
    "print(f\"N's : \\n {N_params}\")\n",
    "print(f\"H's : \\n {H_params}\")\n",
    "print(f\"lambdas's : \\n {lam_params}\")\n",
    "print(f\"alpha's : \\n {alpha_params}\")\n",
    "print(f\"beta's : \\n {beta_params}\")\n",
    "print(f\"gamma's : \\n {gamma_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c01eb-4638-46ee-a119-4ac2d3e91327",
   "metadata": {},
   "source": [
    "After testing, the best parameters for each model is the following:\n",
    "\n",
    "semi-supervised:\n",
    "\n",
    "N = 83, H = 8, lambda = 0.9972622972412019, alpha = 0.29875430006540116, beta = 0.027522971098209642, gamma = 0.5603235966001504\n",
    "\n",
    "supervised:\n",
    "\n",
    "N = 115, H = 28, lam = 0.7027851920001379, alpha = 0.30474592021652713, beta = 0.01810259997923652, gamma = 0.5005044156978288"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1cc54-1a7b-4dad-9925-00b6a5c4f954",
   "metadata": {},
   "source": [
    "Run the cell below to with the optimal parameters for supervised if you wish to do a supervised run, or vice versa for semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125a4d1-cae0-423d-bd98-4f10ca1fb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal parameters for supervised:\n",
    "chunk_size = 115 #N\n",
    "num_of_neurons = 28 #H\n",
    "manifold_reg = 0.7027851920001379 #lam\n",
    "L2_reg = 0.30474592021652713 #alpha\n",
    "RBF_width = 0.01810259997923652 #beta\n",
    "RBFN_width = 0.5005044156978288 #gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07ec36-d8f8-4629-812f-4e2c3968a797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal parameters for semisupervised:\n",
    "'''\n",
    "chunk_size = 83 #N\n",
    "num_of_neurons = 8 #H\n",
    "manifold_reg = 0.9972622972412019 #lam\n",
    "L2_reg = 0.29875430006540116 #alpha\n",
    "RBF_width = 0.027522971098209642 #beta\n",
    "RBFN_width = 0.5603235966001504 #gamma\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1efd52-6e12-46c8-a84a-d035a341a45c",
   "metadata": {},
   "source": [
    "Choose the dataset to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e28738-730c-4bdf-9aff-47eb58c9a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose dataset:\n",
    "data = import_data(\"tomcat-Sort-PreProcess-minmax2-withfix.csv\", delim=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7bbb33-287c-46c1-b90c-71bd49d59da8",
   "metadata": {},
   "source": [
    "Run the code below. Ensure that the 'type' parameter is 0 for semi-supversied, and 1 for supervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1a074-c3ae-4209-9370-f1e3543f4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the timer\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "#predictions, centers, widths, weights = OSNN(type, data, chunk_size, num_of_neurons, manifold_reg, L2_reg, RBF_width, RBFN_width)\n",
    "predictions = OSNN(data, chunk_size, num_of_neurons, manifold_reg, L2_reg, RBF_width, RBFN_width, type = 1)\n",
    "\n",
    "#end the timer\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "#calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917cfe41-5b72-43ea-9905-5d5833c22df6",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88a433-4131-4348-8c1d-8cd874f57652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save it\n",
    "save_to_CSV('brackets_predictions_supervised.csv', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
